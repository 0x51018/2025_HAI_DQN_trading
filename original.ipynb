{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a519ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.0.2 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib==3.9.4 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.9.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 3)) (6.5.2)\n",
      "Requirement already satisfied: filelock in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from torch==2.6.0->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.6.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib==3.9.4->-r requirements.txt (line 3)) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rmrf/miniconda3/envs/hai/lib/python3.9/site-packages (from jinja2->torch==2.6.0->-r requirements.txt (line 4)) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71179c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21db32c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock_splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.099155</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.087136</td>\n",
       "      <td>0.087136</td>\n",
       "      <td>0.086707</td>\n",
       "      <td>0.086707</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>0.089282</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>0.091858</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      open      high       low     close     volume  dividends  \\\n",
       "idx                                                                             \n",
       "1    1980-12-12  0.098726  0.099155  0.098726  0.098726  469033600        0.0   \n",
       "2    1980-12-15  0.094005  0.094005  0.093575  0.093575  175884800        0.0   \n",
       "3    1980-12-16  0.087136  0.087136  0.086707  0.086707  105728000        0.0   \n",
       "4    1980-12-17  0.088853  0.089282  0.088853  0.088853   86441600        0.0   \n",
       "5    1980-12-18  0.091429  0.091858  0.091429  0.091429   73449600        0.0   \n",
       "\n",
       "     stock_splits  \n",
       "idx                \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "5             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"prices/AAPL.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60768690",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e9688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, window_size, trend, skip, batch_size):\n",
    "        self.state_size = state_size\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.action_size = 3\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 0.5\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.999\n",
    "\n",
    "        self.device = torch.device(DEVICE)\n",
    "        self.model = DQNetwork(state_size, self.action_size).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-5)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        state = torch.tensor(state, dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def get_state(self, t):\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d:t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0:t + 1]\n",
    "        res = [block[i + 1] - block[i] for i in range(window_size - 1)]\n",
    "        return np.array(res, dtype=np.float32)\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np.array([transition[0] for transition in mini_batch])\n",
    "        actions = np.array([transition[1] for transition in mini_batch])\n",
    "        rewards = np.array([transition[2] for transition in mini_batch])\n",
    "        next_states = np.array([transition[3] for transition in mini_batch])\n",
    "        dones = np.array([transition[4] for transition in mini_batch])\n",
    "\n",
    "        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(self.device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(self.device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        current_q = self.model(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        next_q = self.model(next_states).max(1)[0].detach()\n",
    "        target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "\n",
    "        loss = self.criterion(current_q, target_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def train(self, episodes):\n",
    "        for episode in range(episodes):\n",
    "            state = self.get_state(0)\n",
    "            total_profit = 0\n",
    "            for t in range(0, len(self.trend) - 1, self.skip):\n",
    "                action = self.act(state)\n",
    "                next_state = self.get_state(t + 1)\n",
    "                reward = 0\n",
    "                done = t == len(self.trend) - 2\n",
    "\n",
    "                if action == 1 and t < (len(self.trend) - self.half_window):\n",
    "                    self.inventory.append(self.trend[t])\n",
    "                    reward = -self.trend[t]\n",
    "                elif action == 2 and len(self.inventory) > 0:\n",
    "                    bought_price = self.inventory.pop(0)\n",
    "                    reward = self.trend[t] - bought_price\n",
    "                    total_profit += reward\n",
    "\n",
    "                self.memory.append((state, action, reward, next_state, done))\n",
    "                state = next_state\n",
    "                \n",
    "                self.replay()\n",
    "\n",
    "            print(f\"Episode {episode + 1}/{episodes}, Total Profit: {total_profit}\")\n",
    "\n",
    "    def buy(self, initial_money):\n",
    "        state = self.get_state(0)\n",
    "        total_balance = initial_money\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            state = self.get_state(t + 1)\n",
    "            if action == 1 and total_balance >= self.trend[t]:\n",
    "                self.inventory.append(self.trend[t])\n",
    "                total_balance -= self.trend[t]\n",
    "            elif action == 2 and len(self.inventory) > 0:\n",
    "                bought_price = self.inventory.pop(0)\n",
    "                total_balance += self.trend[t]\n",
    "\n",
    "        return total_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cbdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10, Total Profit: -0.5343747065999955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      6\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(state_size\u001b[38;5;241m=\u001b[39mwindow_size,\n\u001b[1;32m      7\u001b[0m               window_size\u001b[38;5;241m=\u001b[39mwindow_size,\n\u001b[1;32m      8\u001b[0m               trend\u001b[38;5;241m=\u001b[39mclose,\n\u001b[1;32m      9\u001b[0m               skip\u001b[38;5;241m=\u001b[39mskip,\n\u001b[1;32m     10\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m---> 11\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 104\u001b[0m, in \u001b[0;36mAgent.train\u001b[0;34m(self, episodes)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mappend((state, action, reward, next_state, done))\n\u001b[1;32m    102\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Profit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_profit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m, in \u001b[0;36mAgent.replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m next_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     73\u001b[0m target_q \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q\n\u001b[0;32m---> 75\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/hai/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hai/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hai/lib/python3.9/site-packages/torch/nn/modules/loss.py:610\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hai/lib/python3.9/site-packages/torch/nn/functional.py:3905\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3902\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid reduction mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreduction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3903\u001b[0m         )\n\u001b[1;32m   3904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "close = df.close.values.tolist()\n",
    "initial_money = 10000\n",
    "window_size = 30\n",
    "skip = 1\n",
    "batch_size = 32\n",
    "agent = Agent(state_size=window_size,\n",
    "              window_size=window_size,\n",
    "              trend=close,\n",
    "              skip=skip,\n",
    "              batch_size=batch_size)\n",
    "agent.train(episodes=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
